{"version":3,"file":"static/webpack/static/development/pages/diabetic-retinopathy.js.572909b9f2c38e35a743.hot-update.js","sources":["webpack:///./pages/diabetic-retinopathy.js"],"sourcesContent":["import \"../styles/cutereset.less\";\nimport \"../styles/grid.less\";\n\nimport Head from \"next/head\";\nimport RatioImage from \"../components/ratio-image.js\";\n\nimport TopNav from \"../components/topnav.js\";\nimport Footer from \"../components/footer.js\";\nimport APIViewer from \"../components/apiviewer.js\";\n\nconst DB = [\n  {\n    source: \"./static/assets/diabetic-retinopathy/10004_left.jpg\",\n    data: {\n      label: \"No DR\",\n      sum_r: 0.000285714285714285,\n      sum_y: 0.018857143,\n      red_alert: false,\n      yellow_alert: false,\n      probs: {\n        healthy: 9.08857143e-1,\n        mild: 7.22857143e-2,\n        moderate: 1.85714286e-2,\n        severe: 2.85714286e-4,\n        proliferative: 0.0\n      }\n    }\n  },\n\n  {\n    source: \"./static/assets/diabetic-retinopathy/10062_left.jpg\",\n    data: {\n      label: \"Moderate\",\n      sum_r: 0.072285714,\n      sum_y: 0.618571429,\n      red_alert: false,\n      yellow_alert: true,\n      probs: {\n        healthy: 0.28142857,\n        mild: 0.1,\n        moderate: 0.54628571,\n        severe: 0.04457143,\n        proliferative: 0.02771429\n      }\n    }\n  },\n\n  {\n    source: \"./static/assets/diabetic-retinopathy/10125_right.jpg\",\n    data: {\n      label: \"Severe\",\n      sum_r: 0.029142857,\n      sum_y: 0.731142857,\n      red_alert: false,\n      yellow_alert: true,\n      probs: {\n        healthy: 0.19685714,\n        mild: 0.072,\n        moderate: 0.702,\n        severe: 0.02171429,\n        proliferative: 0.00742857\n      }\n    }\n  },\n\n  {\n    source: \"./static/assets/diabetic-retinopathy/10219_left.jpg\",\n    data: {\n      label: \"Moderate\",\n      sum_r: 0.040285714,\n      sum_y: 0.969714286,\n      red_alert: false,\n      yellow_alert: true,\n      probs: {\n        healthy: 0.00257143,\n        mild: 0.02771429,\n        moderate: 0.92942857,\n        severe: 0.03142857,\n        proliferative: 0.00885714\n      }\n    }\n  },\n\n  {\n    source: \"./static/assets/diabetic-retinopathy/10236_right.jpg\",\n    data: {\n      label: \"Proliferative\",\n      sum_r: 0.458164658,\n      sum_y: 0.999714286,\n      red_alert: true,\n      yellow_alert: true,\n      probs: {\n        healthy: 2.85714286e-4,\n        mild: 0.0,\n        moderate: 5.41549627e-1,\n        severe: 3.35714286e-1,\n        proliferative: 1.22450373e-1\n      }\n    }\n  },\n\n  {\n    source: \"./static/assets/diabetic-retinopathy/10376_left.jpg\",\n    data: {\n      label: \"Mild\",\n      sum_r: 0.011142857,\n      sum_y: 0.424285714,\n      red_alert: false,\n      yellow_alert: true,\n      probs: {\n        healthy: 2.51714286e-1,\n        mild: 3.24e-1,\n        moderate: 4.13142857e-1,\n        severe: 1.08571429e-2,\n        proliferative: 2.85714286e-4\n      }\n    }\n  },\n\n  {\n    source: \"./static/assets/diabetic-retinopathy/10378_right.jpg\",\n    data: {\n      label: \"Proliferative\",\n      sum_r: 0.994,\n      sum_y: 1,\n      red_alert: true,\n      yellow_alert: true,\n      probs: {\n        healthy: 0.0,\n        mild: 0.0,\n        moderate: 0.006,\n        severe: 0.06057143,\n        proliferative: 0.93342857\n      }\n    }\n  },\n\n  {\n    source: \"./static/assets/diabetic-retinopathy/10446_right.jpg\",\n    data: {\n      label: \"Moderate\",\n      sum_r: 0.019714286,\n      sum_y: 0.962,\n      red_alert: false,\n      yellow_alert: true,\n      probs: {\n        healthy: 0.01114286,\n        mild: 0.02685714,\n        moderate: 0.94228571,\n        severe: 0.018,\n        proliferative: 0.00171429\n      }\n    }\n  },\n\n  {\n    source: \"./static/assets/diabetic-retinopathy/10551_right.jpg\",\n    data: {\n      label: \"Mild\",\n      sum_r: 0.001142857,\n      sum_y: 0.075714286,\n      red_alert: false,\n      yellow_alert: true,\n      probs: {\n        healthy: 0.54542857,\n        mild: 0.37885714,\n        moderate: 0.07457143,\n        severe: 0.00114286,\n        proliferative: 0.0\n      }\n    }\n  },\n  {\n    source: \"./static/assets/diabetic-retinopathy/1071_right.jpg\",\n    data: {\n      label: \"Mild\",\n      sum_r: 0.001428571,\n      sum_y: 0.755714286,\n      red_alert: false,\n      yellow_alert: true,\n      probs: {\n        healthy: 2.13142857e-1,\n        mild: 3.11428571e-2,\n        moderate: 7.54285714e-1,\n        severe: 1.14285714e-3,\n        proliferative: 2.85714286e-4\n      }\n    }\n  }\n];\n\nexport default props => (\n  <div className=\"grid\">\n    <Head>\n      <title>Synx - Impact on Healthcare.</title>\n    </Head>\n    <style jsx global>\n      {`\n        .small {\n          font-size: 0.95rem;\n          padding: 0.3rem 0;\n        }\n\n        .study-illustration {\n          margin: 3rem auto;\n          max-width: 640px;\n        }\n      `}\n    </style>\n    <div className=\"grid-content\">\n      <div className=\"grid-header\">\n        <TopNav URL={props.URL} />\n\n        <section className=\"subheader-content\">\n          <h1>Impact on Healthcare.</h1>A case on Diabetic Retinopathy.\n        </section>\n      </div>\n    </div>\n\n    <div className=\"grid-content\">\n\n      By applying Deep Learning and Computer Vision, we can achieve faster diagnostics, which leads to the optimization of the way patients are treated in the whole process and the decision making from the doctor.\n\n      <h2>Abstract</h2>\n      We developed an automatic screening/diagnostic system for diabetic\n      retinopathy using an ensemble of deep neural networks followed by a random\n      forest classifier. Our system has a sensitivity of 95% and a specificity\n      of 65%.\n      <br /><br />\n      <APIViewer data={DB} />\n      <br />\n      <h3>Problem overview</h3>\n      Diabetic retinopathy (DR), a major microvascular complication of diabetes,\n      has a significant impact on the world's health systems. In Mexico alone\n      this disease affects more than 11 million people [1]. Globally, the number\n      of people with DR will grow from 126.6 million in 2010 to 191.0 million by\n      2030, and it is estimated that the number with vision-threatening diabetic\n      retinopathy (VTDR) will increase from 37.3 million to 56.3 million, if\n      prompt action is not taken.\n      <br /><br />\n      Despite growing evidence documenting the\n      effectiveness of routine DR screening and early treatment, DR frequently\n      leads to poor visual functioning and represents the leading cause of\n      blindness in working-age populations. DR has been neglected in health-care\n      research and planning in many low-income countries, where access to\n      trained eye-care professionals and tertiary eye-care services may be\n      inadequate. Demand for, as well as, supply of services may be a problem.\n      Rates of compliance with diabetes medications and annual eye examinations\n      may be low, the reasons for which are multifactorial [2].\n      <br />\n      <br />\n      <h3>Motivation</h3>\n      With the intention of developing an automatic diagnostic system for the\n      screening of patients with possible diabetic retinopathy, we used recent\n      advances in computer vision and deep learning to train an ensamble of\n      neural networks to detect this disease and its level of progression.\n      <br />\n      <br />\n      <br />\n      <h2>Model overview</h2>\n      <h3>Data</h3>\n      For training and validation, we used 85,000 high-resolution images, each one consisting of a digital slit lamp capture, labeled with the proper diagnosis (made by a clinician who rated the severity of the disease). Each image is labeled as being [0] no DR, [1] mild DR, [2] moderate DR, [3] severe DR or [4] proliferative DR. The per-class representation in the dataset is as follows:\n      <table>\n        <thead>\n          <tr>\n            <th>Class</th>\n            <th>Number of images</th>\n          </tr>\n        </thead>\n        <tbody>\n          <tr>\n            <td>No DR</td>\n            <td>62,920</td>\n          </tr>\n          <tr>\n            <td>Mild DR</td>\n            <td>5,650</td>\n          </tr>\n          <tr>\n            <td>Moderate DR</td>\n            <td>12,440</td>\n          </tr>\n          <tr>\n            <td>Severe DR</td>\n            <td>2,020</td>\n          </tr>\n          <tr>\n            <td>Proliferative DR</td>\n            <td>1,690</td>\n          </tr>\n        </tbody>\n      </table>\n      The data was randomly divided between train (90%) and test (10%) sets.\n      Test results were used for early-stopping during training and to choose\n      some metaparameters of the neural networks. An example image from original\n      data. An example image from original data.\n      <br />\n      <br />\n      <div className=\"study-illustration\">\n        <RatioImage src=\"./static/assets/diabetic-retinopathy/normal.jpg\" />\n      </div>\n      <h3>Preprocessing</h3>\n      The eye is detected and the image is rescaled and adjusted so that the eye\n      is always in the center with a fixed size. RGB channels are locally\n      normalized with a moving gaussian kernel in order to highlight local image\n      variability. This allows the model to be agnostic to global light\n      intensity and other factors depending on the particular camera used.\n      <div className=\"study-illustration\">\n        <RatioImage src=\"./static/assets/diabetic-retinopathy/preprocessed.jpg\" />\n      </div>\n      An example image from original data. This image represent the final image\n      from a Proliferative DR study used for neural network training.\n      <br />\n      <br />\n      <h3>Neural Networks</h3>\n      Several neural networks were trained using different architectures\n      (InceptionV3, Resnet50). The training leveraged transfer learning from an\n      Imagenet model, and was done in stages from the top-most layers gradually\n      diminishing the learning rate. Two weeks of 2-gpu servers were used for\n      the training of each model.\n      <div className=\"study-illustration\">\n        <RatioImage src=\"./static/assets/diabetic-retinopathy/heatmap.jpg\" />\n      </div>\n      An example image from original data. After training, a neural network is\n      capable to evaluate preprecessed images, this image shows the heatmap\n      where damage is being found on a Proliferative DR patient.\n      <br />\n      <br />\n      <h3>Random Forest</h3>\n      We trained a Random Forest to combine the results of the different neural\n      networks on both eyes of the patient with other statistics from the\n      images, to predict the final probabilities that a particular image\n      corresponds to a certain level of DR. This stage assigns to each image a\n      vector with the probabilities of each class.\n      <br />\n      <br />\n      <h3>Label aggregation</h3>\n      Most guidelines recommend annual screening for those with no Retinopathy or mild Diabetic Retinopathy; every 6 months for moderate Diabetic Retinopathy, and an Ophthalmologist referral for treatment evaluation within a few weeks or months for severe or proliferative Diabetic retinopathy [3].\n      <br />\n      <br />\n      Following other studies such as [3], we define a negative case as no-DR or\n      mild-DR, and a positive case as moderate, severe or proliferative DR. The\n      vector of probabilities is therefore simplified into the probability of\n      being a positive DR case. We can now create a ROC curve to choose the\n      threshold for our prediction. A family of models with different\n      sensibility and specificity. In figure X we can see the different\n      possibilities. Among these we chose a model with 95% sensitivity and a\n      corresponding 65% specificity so that it serves as a good first screening\n      layer in a diagnostic pipeline.\n      <br />\n      <br />\n      In a similar fashion, we created a Red alert using only severe and\n      proliferative DR as positive cases and looking for a sensitivity of 0.9.\n      These two alerts, yellow and red have the following statistics:\n\n      <div class=\"synx-table-header\">Table 1.</div>\n      <table>\n        <thead>\n          <tr>\n            <th>Class</th>\n            <th>Yellow alert</th>\n            <th>Red alert</th>\n          </tr>\n        </thead>\n        <tbody>\n          <tr>\n            <td>No DR</td>\n            <td>18%</td>\n            <td>1%</td>\n          </tr>\n          <tr>\n            <td>Mild DR</td>\n            <td>57%</td>\n            <td>2%</td>\n          </tr>\n          <tr>\n            <td>Moderate DR</td>\n            <td>90%</td>\n            <td>38%</td>\n          </tr>\n          <tr>\n            <td>Severe DR</td>\n            <td>98%</td>\n            <td>89%</td>\n          </tr>\n          <tr>\n            <td>Proliferative DR</td>\n            <td>98%</td>\n            <td>91%</td>\n          </tr>\n          <tr>\n            <td>No DR or Mild DR</td>\n            <td>\n              <b>35%</b>{\" \"}\n              <div className=\"small\">(general specificity = 65%)</div>\n            </td>\n            <td>1%</td>\n          </tr>\n          <tr>\n            <td>Moderate, Severe or Proliferative</td>\n            <td>\n              <b>95%</b> <div className=\"small\">(general sensivity)</div>\n            </td>\n            <td>50%</td>\n          </tr>\n          <tr>\n            <td>Severe or Proliferative</td>\n            <td>98%</td>\n            <td>90%</td>\n          </tr>\n        </tbody>\n      </table>\n\n      <br />\n      The probability of triggering the Yellow or Red alerts when the patient has a certain class level of Retinopathy. We see that the Red alert is only likely to be triggered with Moderate, Severe or Proliferative DR; while Yellow alert is more conservative and is able to detect 95% of all positive cases. In combination, both alerts can be extremely useful for the early detection of diabetic retinopathy.\n      <br />\n      <br />\n      <h3>Further steps for improving of the model performance:</h3>\n      <ul>\n        <li>\n          A more robust labeling following the example of [3] would definitely\n          decrease the prediction error. In order to do this we will collaborate\n          with a team of ophthalmologists for systematic robust diagnosis and\n          localization of wounds.\n        </li>\n        <li>\n          During the Random Forest stage, the inclusion of additional data from\n          the patients (such as glucose levels, age, etc) would be very\n          valuable.\n        </li>\n        <li>\n          Currently the model uses an ensemble of 3 neural networks. Bringing\n          this to at least 10 could prove very effective in increasing the\n          accuracy of the model. In addition, working with larger (better\n          resolution) images could allow us to detect smaller wounds. These two\n          only amount to having more computing power during training.\n        </li>\n      </ul>\n    </div>\n\n    <Footer hueRotation={props.hueRotation} />\n  </div>\n);\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AALA;AANA;AAFA;AAmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AALA;AANA;AAFA;AAmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AALA;AANA;AAFA;AAmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AALA;AANA;AAFA;AAmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AALA;AANA;AAFA;AAmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AALA;AANA;AAFA;AAmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AALA;AANA;AAFA;AAmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AALA;AANA;AAFA;AAmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AALA;AANA;AAFA;AAkBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AALA;AANA;AAFA;AAmBA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAFA;AAAA;AAAA;AAiBA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAQA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAQA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAIA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAEA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAMA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAKA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAzPA;;;;A","sourceRoot":""}